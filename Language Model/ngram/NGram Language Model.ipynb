{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import gensim, nltk, re, string\n",
    "from collections import Counter\n",
    "import unicodedata as ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    return nltk.tokenize.wordpunct_tokenize(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(token):\n",
    "    return ''.join(c for c in token if not ud.category(c).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_vocab(df):\n",
    "    filtered_df = [[token if counter[token]>5 else unk_token for token in row] for row in df]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_path = '../data/book corpus/book_corpus.txt'\n",
    "corpus = open(corpus_path).read().split('\\n')\n",
    "corpus = [tokenize(row) for row in corpus]\n",
    "corpus_no_punct = [[remove_punct(token) for token in row if remove_punct(token) != ''] for row in corpus]\n",
    "corpus_no_punct = [row for row in corpus_no_punct if len(row) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مونا لیزا کی مسکراہٹ میں کیا بھید ہے ؟ اس کے ہونٹوں پر یہ شفق کا سونا ، سورج کا جشن طلوع ہے یا غروب ہوتے ہوئے آفتاب کا گہرا ملال ؟ ان نیم وا متبسم ہونٹوں کے درمیان یہ باریک سی کالی لکیر کیا ہے ؟ یہ طلوع و غروب کے عین بیچ میں اندھیرے کی آبشار کہاں سے گر رہی ہے ؟ \n",
      "\n",
      "مونا لیزا کی مسکراہٹ میں کیا بھید ہے اس کے ہونٹوں پر یہ شفق کا سونا سورج کا جشن طلوع ہے یا غروب ہوتے ہوئے آفتاب کا گہرا ملال ان نیم وا متبسم ہونٹوں کے درمیان یہ باریک سی کالی لکیر کیا ہے یہ طلوع و غروب کے عین بیچ میں اندھیرے کی آبشار کہاں سے گر رہی ہے\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(corpus[0]),'\\n')\n",
    "print(' '.join(corpus_no_punct[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 7949711\n",
      "Total number of unique tokens: 115202\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for row in corpus_no_punct for token in row]\n",
    "unique_tokens = list(set(tokens))\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Total number of unique tokens:', len(unique_tokens))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '\"س\"'\n",
    "end_token = '\"ش\"'\n",
    "unk_token = '\"انک\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"س\" مونا لیزا کی مسکراہٹ میں کیا بھید ہے اس کے ہونٹوں پر یہ شفق کا سونا سورج کا جشن طلوع ہے یا غروب ہوتے ہوئے آفتاب کا گہرا ملال ان نیم وا متبسم ہونٹوں کے درمیان یہ باریک سی کالی لکیر کیا ہے یہ طلوع و غروب کے عین بیچ میں اندھیرے کی آبشار کہاں سے گر رہی ہے \"ش\"\n"
     ]
    }
   ],
   "source": [
    "corpus_no_punct = [[start_token]+row+[end_token] for row in corpus_no_punct]\n",
    "tokens = [token for row in corpus_no_punct for token in row]\n",
    "counter = Counter(tokens)\n",
    "filtered_corpus = reduce_vocab(corpus_no_punct)\n",
    "print(' '.join(filtered_corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original vocabulary:  115204\n",
      "Size of reduced vocabulary:  29109\n"
     ]
    }
   ],
   "source": [
    "print('Size of original vocabulary: ',len(counter))\n",
    "tokens = [token for row in filtered_corpus for token in row]\n",
    "counter = Counter(tokens)\n",
    "print('Size of reduced vocabulary: ',len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142515, 15836)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus, test_corpus = train_test_split(filtered_corpus,test_size=0.1,random_state=42) \n",
    "len(train_corpus), len(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus, corpus_no_punct, filtered_corpus, counter, tokens, unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29109, 847333881, 24665041942029]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[29109**i for i in range(1,4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Langauge Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, corpus=None):\n",
    "        if corpus is None:\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.fit(corpus)\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        tokens = [token for row in corpus for token in row]\n",
    "        self.num_tokens = len(tokens)\n",
    "        self.model = Counter(tokens)\n",
    "        for token,count in self.model.items():\n",
    "            self.model[token] = count/self.num_tokens\n",
    "        self.V = len(self.model)\n",
    "    \n",
    "    def predict(self, test_corpus):\n",
    "        M = sum([len(row) for row in test_corpus])\n",
    "        l = -np.sum([np.sum(np.log([self.prob(token, unk='\"انک\"') for token in row])) for row in test_corpus]) / M\n",
    "        return 2**l\n",
    "    \n",
    "    def prob(self, token, unk=None):\n",
    "        if unk is None:\n",
    "            return self.model.get(token, 0)            \n",
    "        else:\n",
    "            return self.model.get(token, self.model.get(unk, 0))\n",
    "        \n",
    "    def count(self, token):\n",
    "        return self.model[token]*self.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram()\n",
    "unigram.fit(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.51595575442532"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram():\n",
    "    def __init__(self, corpus = None, smoothing=False, smoothing_val=1, backoff=False, discount_val=0.5):\n",
    "        if corpus is None:\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.fit(corpus)\n",
    "            \n",
    "        self.smoothing = smoothing\n",
    "        self.smoothing_val = smoothing_val\n",
    "        self.backoff = backoff\n",
    "        self.discount_val = discount_val\n",
    "        \n",
    "        assert not ((self.smoothing is True) and (self.backoff is True))\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        self.unigram = Unigram(corpus=corpus)\n",
    "        \n",
    "        corpus = [[tuple(row[i:i+2]) for i in range(len(row)-1)] for row in corpus]\n",
    "        bigram_tokens = [bigram_token for row in corpus for bigram_token in row]  \n",
    "        \n",
    "        self.num_tokens = len(bigram_tokens)\n",
    "        self.V = self.unigram.V**2\n",
    "\n",
    "        self.model = Counter(bigram_tokens)\n",
    "        \n",
    "        # no model smoothing/discounting\n",
    "        if (self.smoothing is False) and (self.backoff is False):\n",
    "            for bigram_token,count in self.model.items():\n",
    "                self.model[bigram_token] = count/self.unigram.count(bigram_token[0])\n",
    "        \n",
    "        # model smoothing\n",
    "        elif (self.smoothing is True) and (self.backoff is False):\n",
    "            for bigram_token,count in self.model.items():\n",
    "                self.model[bigram_token] = (count+self.smoothing_val)/(self.unigram.count(bigram_token[0])+(self.smoothing_val*self.V))\n",
    "                \n",
    "            for token, p in self.unigram.model.items():\n",
    "                self.unigram.model[token] = 1/(self.unigram.count(token)+(self.smoothing_val*self.V))\n",
    "        \n",
    "        # model discounting\n",
    "        elif (self.smoothing is False) and (self.backoff is True):\n",
    "            for bigram_token,count in self.model.items():\n",
    "                self.model[bigram_token] = (count-self.discount_val)/self.unigram.count(bigram_token[0])\n",
    "\n",
    "            alpha = (self.discount_val*len(self.model))/self.num_tokens\n",
    "            M = sum([self.unigram.count(token) for token in self.unigram.model.keys()])\n",
    "            \n",
    "            for token, p in self.unigram.model.items():\n",
    "                self.unigram.model[token] = alpha * self.unigram.count(token)/self.unigram.num_tokens\n",
    "                \n",
    "    def predict(self, test_corpus):\n",
    "        test_corpus = [[tuple(row[i:i+2]) for i in range(len(row)-1)] for row in test_corpus]\n",
    "        M = sum([len(row) for row in test_corpus])\n",
    "        \n",
    "        if (self.smoothing is False) and (self.backoff is False):\n",
    "            l = -np.sum([np.sum(np.log([self.prob(token) for token in row])) for row in test_corpus]) / M\n",
    "        else:\n",
    "            l = -np.sum([np.sum(np.log([self.prob(token, unk='\"انک\"') for token in row])) for row in test_corpus]) / M\n",
    "            \n",
    "        return 2**lz\n",
    "    \n",
    "    def prob(self, token, unk=None):\n",
    "        if unk is None:\n",
    "            return self.model.get(token, 0)            \n",
    "        else:\n",
    "            return self.model.get(token, self.unigram.prob(token[0], unk=unk))\n",
    "        \n",
    "    def count(self, token):\n",
    "        if (self.smoothing is False) and (self.backoff is False):\n",
    "            return self.model[token]*self.unigram.count(token[0])\n",
    "        elif (self.smoothing is True) and (self.backoff is False):\n",
    "            return (self.model[token]*(self.unigram.count(token[0])+(self.smoothing_val*self.V)))-self.smoothing_val\n",
    "        elif (self.smoothing is False) and (self.backoff is True):\n",
    "            return (self.model[token]*self.unigram.count(token[0]))+self.discount_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osamaqureshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  inf\n"
     ]
    }
   ],
   "source": [
    "bigram = Bigram()\n",
    "bigram.fit(train_corpus)\n",
    "print('Perplexity: ', bigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  96119.63410999677\n"
     ]
    }
   ],
   "source": [
    "bigram = Bigram(smoothing=True)\n",
    "bigram.fit(train_corpus)\n",
    "print('Perplexity: ', bigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  876.6444731553388\n"
     ]
    }
   ],
   "source": [
    "bigram = Bigram(smoothing=True, smoothing_val=0.001)\n",
    "bigram.fit(train_corpus)\n",
    "print('Perplexity: ', bigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  80.15561471602935\n"
     ]
    }
   ],
   "source": [
    "bigram = Bigram(smoothing=True, smoothing_val=1e-5)\n",
    "bigram.fit(train_corpus)\n",
    "print('Perplexity: ', bigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  49.855559635033465\n"
     ]
    }
   ],
   "source": [
    "bigram = Bigram(backoff=True)\n",
    "bigram.fit(train_corpus)\n",
    "print('Perplexity: ', bigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trigram():\n",
    "    def __init__(self, corpus=None, smoothing=False, smoothing_val=1, backoff=False, discount_val=0.5):\n",
    "        if corpus is None:\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.fit(corpus)\n",
    "            \n",
    "        self.smoothing = smoothing\n",
    "        self.smoothing_val = smoothing_val\n",
    "        self.backoff = backoff\n",
    "        self.discount_val = discount_val\n",
    "        \n",
    "        assert not ((self.smoothing is True) and (self.backoff is True))\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        self.bigram = Bigram(smoothing=self.smoothing, smoothing_val=self.smoothing_val, backoff=self.backoff, discount_val=self.discount_val)\n",
    "        self.bigram.fit(corpus)\n",
    "        \n",
    "        corpus = [[tuple(row[i:i+3]) for i in range(len(row)-2)] for row in corpus]\n",
    "        trigram_tokens = [trigram_token for row in corpus for trigram_token in row]  \n",
    "        \n",
    "        self.num_tokens = len(trigram_tokens)\n",
    "        self.V = self.bigram.unigram.V**3\n",
    "\n",
    "        self.model = Counter(trigram_tokens)\n",
    "        \n",
    "        if (self.smoothing is False) and (self.backoff is False):\n",
    "            for trigram_token,count in self.model.items():\n",
    "                self.model[trigram_token] = count/self.bigram.count(trigram_token[:2])\n",
    "        \n",
    "        elif (self.smoothing is True) and (self.backoff is False):\n",
    "            for trigram_token,count in self.model.items():\n",
    "                self.model[trigram_token] = (count+self.smoothing_val)/(self.bigram.count(trigram_token[:2])+(self.smoothing_val*self.V))\n",
    "                \n",
    "            for token, p in self.bigram.model.items():\n",
    "                self.bigram.model[token] = 1/(self.bigram.count(token)+(self.smoothing_val*self.V))\n",
    "                \n",
    "        elif (self.smoothing is False) and (self.backoff is True):\n",
    "            for trigram_token,count in self.model.items():\n",
    "                self.model[trigram_token] = (count-self.discount_val)/self.bigram.count(trigram_token[:2])\n",
    "\n",
    "            alpha = (self.discount_val*len(self.model))/self.num_tokens\n",
    "            M = sum([self.bigram.count(token) for token in self.bigram.model.keys()])\n",
    "            \n",
    "            for token, p in self.bigram.model.items():\n",
    "                self.bigram.model[token] = alpha * self.bigram.count(token)/self.bigram.num_tokens\n",
    "                \n",
    "    def predict(self, test_corpus):\n",
    "        test_corpus = [[tuple(row[i:i+3]) for i in range(len(row)-2)] for row in test_corpus]\n",
    "        M = sum([len(row) for row in test_corpus])\n",
    "        \n",
    "        if (self.smoothing is False) and (self.backoff is False):\n",
    "            l = -np.sum([np.sum(np.log([self.prob(token) for token in row])) for row in test_corpus]) / M\n",
    "        else:\n",
    "            l = -np.sum([np.sum(np.log([self.prob(token, unk='\"انک\"') for token in row])) for row in test_corpus]) / M\n",
    "            \n",
    "        return 2**l\n",
    "    \n",
    "    def prob(self, token, unk=None):\n",
    "        if unk is None:\n",
    "            return self.model.get(token, 0)            \n",
    "        else:\n",
    "            return self.model.get(token, self.bigram.prob(token[:2], unk=unk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V  29108 847275664 24662500027712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osamaqureshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  inf\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram()\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  331407611.39817506\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(smoothing=True)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  3015852.8945301343\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(smoothing=True, smoothing_val=0.001)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  128855.96118349521\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(smoothing=True, smoothing_val=1e-5)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  386.15454132013974\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(smoothing=True, smoothing_val=1e-9)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  200.6903463255154\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(backoff=True)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  194.58949638277534\n"
     ]
    }
   ],
   "source": [
    "trigram = Trigram(backoff=True, discount_val=0.7)\n",
    "trigram.fit(train_corpus)\n",
    "print('Perplexity: ', trigram.predict(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram_LM():\n",
    "    \n",
    "    def __init__(self, n, corpus=None, train=True, smoothing=False, smoothing_val=1, backoff=False, discount_val=0.5, reduced_vocab=True, unk_token='\"انک\"'):\n",
    "        self.n = n\n",
    "        self.is_unigram = self.n == 1\n",
    "            \n",
    "        self.train = train\n",
    "        self.smoothing = smoothing\n",
    "        self.smoothing_val = smoothing_val\n",
    "        self.backoff = backoff\n",
    "        self.discount_val = discount_val\n",
    "        self.reduced_vocab = reduced_vocab\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        if corpus is None:\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.fit(corpus)\n",
    "            \n",
    "        assert not ((self.smoothing is True) and (self.backoff is True))\n",
    "        \n",
    "    def fit(self, corpus):\n",
    "        \n",
    "        if self.is_unigram is True:\n",
    "            \n",
    "            ngrams = [ngram for row in corpus for ngram in row]\n",
    "            self.num_ngrams = len(ngrams)\n",
    "            self.model = Counter(ngrams)\n",
    "            self.V = len(self.model)\n",
    "            \n",
    "            if self.train is True:\n",
    "                self.compute_probabilities()\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            self._backoff_model = NGram_LM(self.n-1, corpus=corpus, train=False, smoothing=self.smoothing, smoothing_val=self.smoothing_val, backoff=self.backoff, discount_val=self.discount_val)\n",
    "            \n",
    "            corpus_vocab = len([ngram for row in corpus for ngram in row])\n",
    "            ngram_corpus = [[tuple(row[i:i+self.n]) for i in range(len(row)-self.n-1)] for row in corpus]\n",
    "            ngrams = [ngram for row in ngram_corpus for ngram in row]\n",
    "            del ngram_corpus\n",
    "\n",
    "            self.num_ngrams = len(ngrams)\n",
    "            self.V = corpus_vocab**self.n\n",
    "\n",
    "            self.model = Counter(ngrams)\n",
    "\n",
    "            if self.train is True:\n",
    "                self.compute_probabilities()\n",
    "                \n",
    "            \n",
    "    def compute_probabilities(self):\n",
    "        if self.is_unigram is True:\n",
    "            \n",
    "            for ngrams, count in self.model.items():\n",
    "                self.model[ngrams] = count/self.num_ngrams\n",
    "                    \n",
    "        else:\n",
    "            if (self.smoothing is False) and (self.backoff is False):\n",
    "                if self._backoff_model.is_unigram:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = count/self._backoff_model.model[ngram[0]]\n",
    "                else:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = count/self._backoff_model.model[ngram[:self.n-1]]\n",
    "                        \n",
    "            elif (self.smoothing is True) and (self.backoff is False):\n",
    "                \n",
    "                if self._backoff_model.is_unigram:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = (count+self.smoothing_val)/(self._backoff_model.model[ngram[0]]+(self.smoothing_val*self.V))\n",
    "                else:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = (count+self.smoothing_val)/(self._backoff_model.model[ngram[:self.n-1]]+(self.smoothing_val*self.V))\n",
    "\n",
    "                for ngram, count in self._backoff_model.model.items():\n",
    "                    self._backoff_model.model[ngram] = self.smoothing_val/(count+(self.smoothing_val*self.V))\n",
    "\n",
    "                \n",
    "            elif (self.smoothing is False) and (self.backoff is True):\n",
    "                \n",
    "                if self._backoff_model.is_unigram:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = (count-self.discount_val)/self._backoff_model.model[ngram[0]]\n",
    "                else:\n",
    "                    for ngram, count in self.model.items():\n",
    "                        self.model[ngram] = (count-self.discount_val)/self._backoff_model.model[ngram[:self.n-1]]\n",
    "\n",
    "                self.alpha = (self.discount_val*len(self.model))/self.num_ngrams\n",
    "                M = sum(self._backoff_model.model.values())\n",
    "\n",
    "                for ngram, count in self._backoff_model.model.items():\n",
    "                    self._backoff_model.model[ngram] = self.alpha * count/self._backoff_model.num_ngrams\n",
    "      \n",
    "    def prob(self, ngram):\n",
    "        \n",
    "        if self.is_unigram:\n",
    "            return self.unigram_prob(ngram)\n",
    "            \n",
    "        else:\n",
    "            if (self.smoothing is False) and (self.backoff is False):\n",
    "                return self.model.get(ngram, 0)\n",
    "            else:                \n",
    "                if self._backoff_model.is_unigram:\n",
    "                    return self.model.get(ngram, self._backoff_model.unigram_prob(ngram[0]))\n",
    "                else:\n",
    "                    return self.model.get(ngram, self._backoff_model.prob(ngram[:self.n-1]))        \n",
    "         \n",
    "    def unigram_prob(self, ngram):\n",
    "        if self.reduced_vocab:\n",
    "            return self.model.get(ngram, self.model[self.unk_token])            \n",
    "        else:\n",
    "            return self.model.get(ngram, 0)    \n",
    "            \n",
    "    def perplexity(self, test_corpus):\n",
    "        if self.is_unigram is False:   \n",
    "            test_corpus = [[tuple(row[i:i+self.n]) for i in range(len(row)-self.n-1)] for row in test_corpus]\n",
    "            \n",
    "        M = sum([len(row) for row in test_corpus])\n",
    "        l = -np.sum([np.sum(np.log([self.prob(ngram) for ngram in row])) for row in test_corpus]) / M\n",
    "            \n",
    "        return 2**l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  119.83675041373233\n"
     ]
    }
   ],
   "source": [
    "# Unigram\n",
    "model = NGram_LM(n=1)\n",
    "model.fit(train_corpus)\n",
    "print('Perplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osamaqureshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:120: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  inf\n"
     ]
    }
   ],
   "source": [
    "# Bigram\n",
    "model = NGram_LM(n=2)\n",
    "model.fit(train_corpus)\n",
    "print('Perplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \tPerplexity:  220209624.11635014\n",
      "0.001 \tPerplexity:  3482075.176018939\n",
      "1e-06 \tPerplexity:  52003.43720722636\n"
     ]
    }
   ],
   "source": [
    "# Bigram with smoothing\n",
    "for val in [1, 1e-3, 1e-6, 1e-10]:\n",
    "    model = NGram_LM(n=2, smoothing=True, smoothing_val=val)\n",
    "    model.fit(train_corpus)\n",
    "    print(val, '\\tPerplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  51.01568008195498\n"
     ]
    }
   ],
   "source": [
    "# Bigram with backoff\n",
    "model = NGram_LM(n=2, backoff=True)\n",
    "model.fit(train_corpus)\n",
    "print('Perplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osamaqureshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:120: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  inf\n"
     ]
    }
   ],
   "source": [
    "# Trigram\n",
    "model = NGram_LM(n=3)\n",
    "model.fit(train_corpus)\n",
    "print('Perplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \tPerplexity:  853816356246.01\n",
      "0.001 \tPerplexity:  82956831813.16142\n",
      "1e-06 \tPerplexity:  7381474896.397572\n"
     ]
    }
   ],
   "source": [
    "# Trigram with smoothing\n",
    "for val in [1, 1e-3, 1e-6, 1e-10]:\n",
    "    model = NGram_LM(n=3, smoothing=True, smoothing_val=val)\n",
    "    model.fit(train_corpus)\n",
    "    print(val, '\\tPerplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  61.33946116892834\n"
     ]
    }
   ],
   "source": [
    "# Trigram with backoff\n",
    "model = NGram_LM(n=3, backoff=True)\n",
    "model.fit(train_corpus)\n",
    "print('Perplexity: ', model.perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
